{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rmJW2Nw_4lKg","executionInfo":{"status":"ok","timestamp":1736189171562,"user_tz":-300,"elapsed":3247,"user":{"displayName":"Hanzallah Ahmed Khan","userId":"17527532292942797708"}},"outputId":"1771b22e-c094-4ce8-90a4-ba9ba390dadf"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install dask"],"metadata":{"id":"BuiSJzc45NJA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"id":"OlxAijjx4PUA","executionInfo":{"status":"ok","timestamp":1736189175251,"user_tz":-300,"elapsed":27,"user":{"displayName":"Hanzallah Ahmed Khan","userId":"17527532292942797708"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import dask.dataframe as dd\n","from multiprocessing import Pool, cpu_count\n","from time import time"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2sWfrU9h4PUM","executionInfo":{"status":"ok","timestamp":1736189203806,"user_tz":-300,"elapsed":15813,"user":{"displayName":"Hanzallah Ahmed Khan","userId":"17527532292942797708"}},"outputId":"36cb3914-67ca-4881-a05c-5b20d207fb05"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running multiprocessing...\n","Multiprocessing completed in 9.15 seconds\n","Running Dask...\n","Dask completed in 6.24 seconds\n"]}],"source":["def preprocess_chunk(chunk):\n","    \"\"\"Preprocess a single chunk of data containing date and temperature_2m.\"\"\"\n","    chunk['date'] = pd.to_datetime(chunk['date'], errors='coerce')\n","    chunk = chunk.dropna(subset=['temperature_2m'])\n","    chunk['temperature_2m_normalized'] = (chunk['temperature_2m'] - chunk['temperature_2m'].mean()) / chunk['temperature_2m'].std()\n","    return chunk\n","\n","def parallel_process_multiprocessing(file_path, chunksize):\n","    \"\"\"Preprocess data in parallel using multiprocessing.\"\"\"\n","    start_time = time()\n","    chunks = pd.read_csv(file_path, chunksize=chunksize)\n","\n","    with Pool(cpu_count()) as pool:\n","        processed_chunks = pool.map(preprocess_chunk, chunks)\n","\n","    # Concatenate all processed chunks\n","    result = pd.concat(processed_chunks)\n","\n","    # Save the processed data to a CSV file\n","    result.to_csv(\"/content/drive/MyDrive/P&DC /Theory/project/processed_multiprocessing.csv\", index=False)\n","\n","    print(f\"Multiprocessing completed in {time() - start_time:.2f} seconds\")\n","\n","def parallel_process_dask(file_path):\n","    \"\"\"Preprocess data in parallel using Dask.\"\"\"\n","    start_time = time()\n","\n","    dask_df = dd.read_csv(file_path)\n","    dask_df = dask_df.map_partitions(preprocess_chunk)\n","    dask_df.compute().to_csv(\"/content/drive/MyDrive/P&DC /Theory/project/processed_dask.csv\", index=False)\n","\n","    print(f\"Dask completed in {time() - start_time:.2f} seconds\")\n","\n","if __name__ == \"__main__\":\n","    input_file = \"/content/drive/MyDrive/P&DC /Theory/project/data.csv\"\n","\n","    print(\"Running multiprocessing...\")\n","    parallel_process_multiprocessing(input_file, chunksize=10000)\n","\n","    print(\"Running Dask...\")\n","    parallel_process_dask(input_file)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZGnnm2qv4PUP"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}